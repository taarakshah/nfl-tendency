{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d620ecf2",
   "metadata": {},
   "source": [
    "# NFL Data Models and Results\n",
    "\n",
    "This notebook will go through the methodology of data collection, cleaning, and return a finished dataset of a narrowed-down analysis to passing/running plays in the 2018 NFL season. The data is obtained from the NFL's 2020 and 2021 Big Data Bowl:\n",
    "\n",
    "*There is potential to combine the 2020 data bowl data, which contains similar info to 2021 data bowl data except about rushing plays 2017-2019. Combining these sources to produce a similar notebook to the original tendency analysis. Less data, but more information in our columns.*\n",
    "\n",
    "The main focus of this analysis is to see how offensive / defensive personnel and the formation and defensive players on the field affect the decision to run or pass the ball. This can be a unique opportunity to utilize tracking / location data of players as well (which may be explored in a separate notebook).\n",
    "\n",
    "Data bowls for reference:\n",
    "- https://www.kaggle.com/c/nfl-big-data-bowl-2020: Forecast yardage gained on the run plays\n",
    "- https://www.kaggle.com/c/nfl-big-data-bowl-2021/: Forecast yardage gained on pass plays\n",
    "- https://www.kaggle.com/c/nfl-big-data-bowl-2022: Analyze special teams data\n",
    "- https://github.com/nfl-football-ops/Big-Data-Bowl: Inaugural data bowl from 2019, useful R code on animation of tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9c8a62de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4e4d2da6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cleaned dataset for general models\n",
    "bdb = pd.read_csv('bdb_2018_dummy.csv')\n",
    "\n",
    "# Split response vs train data\n",
    "bdb_y = np.where(bdb['Type']=='run', 1, 0) ## convert response variable to 1 for run, 0 for pass\n",
    "bdb_x = bdb.drop(['Type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb92cf9",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "In this section, we train 3 models on the train/test split: logistic regression model, random forest model, and gradient-boosted decision trees with XGBoost.\n",
    "\n",
    "We do this on a train/test split of 75/25.\n",
    "\n",
    "To do:\n",
    "- K-fold cross-validation\n",
    "- Tune hyperparameters...these are the absolute most bare versions of these models so far.\n",
    "- Identify important features in prediction\n",
    "- Set up a function to train these models at once\n",
    "\n",
    "Other ideas:\n",
    "- Segment the data by the position on the field (i.e. train a model for prediction when team is between their 0-20, then their own 20-50, then opposing 50-80, then redzone on opposing 20)\n",
    "- Train models by team on offense\n",
    "- Train models by down #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "da5e91e2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 21439\n",
      "Test Rows: 7147\n"
     ]
    }
   ],
   "source": [
    "# Create train / test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(bdb_x, bdb_y, test_size=0.25, random_state=2022)\n",
    "print('Training Rows: {}\\nTest Rows: {}'.format(x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ff616d53",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshah\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "c3252eb2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train RF model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "e4f6d648",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:02:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train XGBoost model\n",
    "xgc = xgb.XGBClassifier()\n",
    "xgc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee1dd33",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "aced5825",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6215979850276359"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- (sum(bdb_y) / len(bdb_y)) ## Benchmark: We can get 62.16% success rate just guessing pass every play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "2e668d74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412900517699734\n",
      "[[3668  767]\n",
      " [1082 1630]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      4435\n",
      "           1       0.68      0.60      0.64      2712\n",
      "\n",
      "    accuracy                           0.74      7147\n",
      "   macro avg       0.73      0.71      0.72      7147\n",
      "weighted avg       0.74      0.74      0.74      7147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict logistic regression\n",
    "y_pred = lr.predict(x_test)\n",
    "print(lr.score(x_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "735da731",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7464670491115153\n",
      "[[3593  842]\n",
      " [ 970 1742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      4435\n",
      "           1       0.67      0.64      0.66      2712\n",
      "\n",
      "    accuracy                           0.75      7147\n",
      "   macro avg       0.73      0.73      0.73      7147\n",
      "weighted avg       0.74      0.75      0.75      7147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict RF\n",
    "y_pred = rf.predict(x_test)\n",
    "print(rf.score(x_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9f27b004",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7503847768294389\n",
      "[[3558  877]\n",
      " [ 907 1805]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      4435\n",
      "           1       0.67      0.67      0.67      2712\n",
      "\n",
      "    accuracy                           0.75      7147\n",
      "   macro avg       0.73      0.73      0.73      7147\n",
      "weighted avg       0.75      0.75      0.75      7147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict XGB\n",
    "y_pred = xgc.predict(x_test)\n",
    "print(xgc.score(x_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
