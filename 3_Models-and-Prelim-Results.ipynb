{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6d6ecb3",
   "metadata": {},
   "source": [
    "# NFL Data Models and Results\n",
    "\n",
    "This notebook will go through the methodology of model training on various subsets of the cleaned data and return a summary of analysis to passing/running plays in the 2018 NFL season. The data is obtained from the NFL's 2020 and 2021 Big Data Bowl.\n",
    "\n",
    "The main focus of this analysis is to see how offensive / defensive personnel and the formation and defensive players on the field affect the decision to run or pass the ball. This can be a unique opportunity to utilize tracking / location data of players as well (which may be explored in a separate notebook).\n",
    "\n",
    "Data bowls for reference:\n",
    "- https://www.kaggle.com/c/nfl-big-data-bowl-2020: Forecast yardage gained on the run plays\n",
    "- https://www.kaggle.com/c/nfl-big-data-bowl-2021/: Forecast yardage gained on pass plays\n",
    "- https://www.kaggle.com/c/nfl-big-data-bowl-2022: Analyze special teams data\n",
    "- https://github.com/nfl-football-ops/Big-Data-Bowl: Inaugural data bowl from 2019, useful R code on animation of tracking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "66c0bdfb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix, classification_report\n",
    "import xgboost as xgb\n",
    "import os\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.options.mode.chained_assignment = None  # default='warn'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d16989ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read in cleaned dataset for general models\n",
    "bdb = pd.read_csv('bdb_2018_dummy.csv')\n",
    "\n",
    "# Split response vs train data\n",
    "bdb_y = np.where(bdb['Type']=='run', 1, 0) ## convert response variable to 1 for run, 0 for pass\n",
    "bdb_x = bdb.drop(['Type'], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccb92cf9",
   "metadata": {},
   "source": [
    "# Models\n",
    "\n",
    "In this section, we train 3 models on the train/test split: logistic regression model, random forest model, and gradient-boosted decision trees with XGBoost.\n",
    "\n",
    "We do this on a train/test split of 75/25.\n",
    "\n",
    "To do:\n",
    "- K-fold cross-validation\n",
    "- Tune hyperparameters...these are the absolute most bare versions of these models so far.\n",
    "- Identify important features in prediction\n",
    "- Set up a function to train these models at once\n",
    "\n",
    "Other ideas:\n",
    "- Segment the data by the position on the field (i.e. train a model for prediction when team is between their 0-20, then their own 20-50, then opposing 50-80, then redzone on opposing 20)\n",
    "- Train models by team on offense\n",
    "- Train models by down #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "cbda370b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Rows: 21439\n",
      "Test Rows: 7147\n"
     ]
    }
   ],
   "source": [
    "# Create train / test split\n",
    "x_train, x_test, y_train, y_test = train_test_split(bdb_x, bdb_y, test_size=0.25, random_state=2022)\n",
    "print('Training Rows: {}\\nTest Rows: {}'.format(x_train.shape[0], x_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "154025eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\tshah\\Anaconda3\\lib\\site-packages\\sklearn\\linear_model\\_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train Logistic Regression model\n",
    "lr = LogisticRegression()\n",
    "lr.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "35f0d04e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train RF model\n",
    "rf = RandomForestClassifier()\n",
    "rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "9461c9e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[08:02:46] WARNING: C:/Users/Administrator/workspace/xgboost-win64_release_1.5.1/src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'binary:logistic' was changed from 'error' to 'logloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
       "              gamma=0, gpu_id=-1, importance_type=None,\n",
       "              interaction_constraints='', learning_rate=0.300000012,\n",
       "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
       "              monotone_constraints='()', n_estimators=100, n_jobs=8,\n",
       "              num_parallel_tree=1, predictor='auto', random_state=0,\n",
       "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, subsample=1,\n",
       "              tree_method='exact', validate_parameters=1, verbosity=None)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Train XGBoost model\n",
    "xgc = xgb.XGBClassifier()\n",
    "xgc.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bc743b1",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "7efa38b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6215979850276359"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "1- (sum(bdb_y) / len(bdb_y)) ## Benchmark: We can get 62.16% success rate just guessing pass every play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c6b5b7e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7412900517699734\n",
      "[[3668  767]\n",
      " [1082 1630]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.77      0.83      0.80      4435\n",
      "           1       0.68      0.60      0.64      2712\n",
      "\n",
      "    accuracy                           0.74      7147\n",
      "   macro avg       0.73      0.71      0.72      7147\n",
      "weighted avg       0.74      0.74      0.74      7147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict logistic regression\n",
    "y_pred = lr.predict(x_test)\n",
    "print(lr.score(x_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "61f70aa6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7464670491115153\n",
      "[[3593  842]\n",
      " [ 970 1742]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.79      0.81      0.80      4435\n",
      "           1       0.67      0.64      0.66      2712\n",
      "\n",
      "    accuracy                           0.75      7147\n",
      "   macro avg       0.73      0.73      0.73      7147\n",
      "weighted avg       0.74      0.75      0.75      7147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict RF\n",
    "y_pred = rf.predict(x_test)\n",
    "print(rf.score(x_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "9b489d9d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7503847768294389\n",
      "[[3558  877]\n",
      " [ 907 1805]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.80      0.80      4435\n",
      "           1       0.67      0.67      0.67      2712\n",
      "\n",
      "    accuracy                           0.75      7147\n",
      "   macro avg       0.73      0.73      0.73      7147\n",
      "weighted avg       0.75      0.75      0.75      7147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## Predict XGB\n",
    "y_pred = xgc.predict(x_test)\n",
    "print(xgc.score(x_test, y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "eb1d6371",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-57-3cfda733b884>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mplot\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimportance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxgc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'plot' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d97020f1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73e01cc7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5d6dc81b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.6363509164684483\n",
      "[[4272  163]\n",
      " [2436  276]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.96      0.77      4435\n",
      "           1       0.63      0.10      0.18      2712\n",
      "\n",
      "    accuracy                           0.64      7147\n",
      "   macro avg       0.63      0.53      0.47      7147\n",
      "weighted avg       0.63      0.64      0.54      7147\n",
      "\n"
     ]
    }
   ],
   "source": [
    "lr.fit(x_train[['Down','Distance']], y_train)\n",
    "y_pred = lr.predict(x_test[['Down','Distance']])\n",
    "print(lr.score(x_test[['Down','Distance']], y_test))\n",
    "print(confusion_matrix(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e45b01d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
